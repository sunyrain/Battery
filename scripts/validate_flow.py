#!/usr/bin/env python
"""
Flow Matching æ¨¡å‹éªŒè¯è„šæœ¬

éªŒè¯å†…å®¹:
1. è½¨è¿¹é‡å»ºè´¨é‡ - ç»™å®š (z_0, z_1)ï¼Œé¢„æµ‹çš„è½¨è¿¹ z_T æ˜¯å¦æ¥è¿‘ z_1
2. å¥åº·è¯„åˆ†æ›²çº¿ - é¢„æµ‹çš„é€€åŒ–æ›²çº¿æ˜¯å¦ç¬¦åˆç‰©ç†æ„ä¹‰
3. æ½œç©ºé—´å¯è§†åŒ– - é™ç»´åæŸ¥çœ‹è½¨è¿¹åˆ†å¸ƒ
4. RUL é¢„æµ‹ç²¾åº¦ - å¯¹å·²çŸ¥ç”Ÿå‘½å‘¨æœŸçš„æ ·æœ¬è¯„ä¼° RUL é¢„æµ‹

ä½¿ç”¨æ–¹æ³•:
    python scripts/validate_flow.py --checkpoint experiments/flow_matching/checkpoints/best_model.pt
"""

import os
import sys
import argparse
import logging
import torch
import numpy as np
import pandas as pd
from pathlib import Path

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.flow_matching.models.flow_model import BatteryFlowModel, BatteryFlowConfig
from src.flow_matching.core.ode_solver import create_solver
from src.flow_matching.data.latent_cache import LatentCache
from src.flow_matching.utils.config import load_config
from src.smartwavev9 import DeltaBatteryModel

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_encoder(checkpoint_path: str, device: torch.device):
    """åŠ è½½é¢„è®­ç»ƒ Encoder"""
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    
    # è·å–é…ç½®
    if 'config' in checkpoint and 'model' in checkpoint['config']:
        model_cfg = checkpoint['config']['model']['model_config']
    else:
        model_cfg = {'d_model': 256, 'nhead': 4, 'num_layers': 1}
    
    encoder = DeltaBatteryModel(
        input_dim=model_cfg.get('input_dim', 1),
        d_model=model_cfg.get('d_model', 256),
        nhead=model_cfg.get('nhead', 4),
        num_layers=model_cfg.get('num_layers', 1),
        ROPE_max_len=model_cfg.get('ROPE_max_len', 5000),
        num_classes=model_cfg.get('num_classes', 4),
        task_type=model_cfg.get('task_type', 'classification'),
        max_level=model_cfg.get('max_level', 6),
        wavelet=model_cfg.get('wavelet', 'sym4'),
        patch_size=model_cfg.get('patch_size', 10),
        stride=model_cfg.get('stride', 10),
        dropout=model_cfg.get('dropout', 0.2),
    )
    
    state_dict = checkpoint.get('model_state_dict', checkpoint)
    if any(k.startswith('model.') for k in state_dict.keys()):
        state_dict = {k[6:]: v for k, v in state_dict.items() if k.startswith('model.')}
    
    # é¢„åˆ›å»ºæŠ•å½±å±‚
    for key in state_dict.keys():
        if key.startswith('freq_branch.channel_projections.') and key.endswith('.weight'):
            name = key.split('.')[2]
            weight = state_dict[key]
            encoder.freq_branch.channel_projections[name] = torch.nn.Linear(weight.shape[1], weight.shape[0])
    
    # è¿‡æ»¤æ—§å‚æ•°
    keys_to_ignore = {'beta1', 'beta2_offset'}
    state_dict = {k: v for k, v in state_dict.items() if k not in keys_to_ignore}
    
    encoder.load_state_dict(state_dict, strict=False)
    encoder.to(device)
    encoder.eval()
    
    return encoder, model_cfg.get('d_model', 256)


def load_flow_model(checkpoint_path: str, encoder: torch.nn.Module, latent_dim: int, device: torch.device):
    """åŠ è½½ Flow Matching æ¨¡å‹"""
    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    
    # ä»æ£€æŸ¥ç‚¹è·å–é…ç½®
    if 'config' in checkpoint:
        cfg = checkpoint['config']
        config = BatteryFlowConfig(
            latent_dim=cfg.get('latent_dim', latent_dim),
            hidden_dim=cfg.get('hidden_dim', 512),
            num_layers=cfg.get('num_layers', 6),
            max_cycle=cfg.get('max_cycle', 100),
        )
    else:
        config = BatteryFlowConfig(latent_dim=latent_dim)
    
    model = BatteryFlowModel(config, encoder)
    
    # ä¼˜å…ˆåŠ è½½ EMA æƒé‡
    if 'ema_state_dict' in checkpoint:
        model.velocity_net.load_state_dict(checkpoint['ema_state_dict'])
        logger.info("ä½¿ç”¨ EMA æƒé‡")
    elif 'model_state_dict' in checkpoint:
        model.velocity_net.load_state_dict(checkpoint['model_state_dict'])
    
    model.to(device)
    model.eval()
    
    return model, config


@torch.no_grad()
def validate_trajectory_reconstruction(model, latent_vectors, cycles, num_samples=100, device='cuda'):
    """
    éªŒè¯ 1: è½¨è¿¹é‡å»ºè´¨é‡
    
    å¯¹äºéšæœºé‡‡æ ·çš„ (z_0, z_1) å¯¹ï¼Œä» z_0 ç§¯åˆ†åˆ° t=1ï¼Œæ£€æŸ¥æ˜¯å¦æ¥è¿‘ z_1
    """
    logger.info("=" * 60)
    logger.info("éªŒè¯ 1: è½¨è¿¹é‡å»ºè´¨é‡")
    logger.info("=" * 60)
    
    n = len(cycles)
    errors = []
    relative_errors = []
    
    for _ in range(num_samples):
        # éšæœºé€‰æ‹©ä¸€å¯¹
        idx_0 = np.random.randint(n)
        cycle_0 = cycles[idx_0].item()
        
        # æ‰¾ä¸€ä¸ªè¾ƒæ™šçš„ cycle
        valid_mask = (cycles - cycle_0 >= 10) & (cycles - cycle_0 <= 50)
        valid_indices = torch.where(valid_mask)[0]
        
        if len(valid_indices) == 0:
            continue
        
        idx_1 = valid_indices[np.random.randint(len(valid_indices))].item()
        cycle_1 = cycles[idx_1].item()
        
        z_0 = latent_vectors[idx_0:idx_0+1].to(device)
        z_1 = latent_vectors[idx_1:idx_1+1].to(device)
        
        # ç§¯åˆ†é¢„æµ‹
        t_span = torch.linspace(0, 1, 50, device=device)
        trajectory = model.predict_trajectory(z_0, t_span)
        z_pred = trajectory[-1]  # æœ€ç»ˆé¢„æµ‹
        
        # è®¡ç®—è¯¯å·®
        error = torch.norm(z_pred - z_1).item()
        z_1_norm = torch.norm(z_1).item()
        rel_error = error / (z_1_norm + 1e-8)
        
        errors.append(error)
        relative_errors.append(rel_error)
    
    if errors:
        logger.info(f"  é‡‡æ ·æ•°: {len(errors)}")
        logger.info(f"  ç»å¯¹è¯¯å·®: {np.mean(errors):.4f} Â± {np.std(errors):.4f}")
        logger.info(f"  ç›¸å¯¹è¯¯å·®: {np.mean(relative_errors):.2%} Â± {np.std(relative_errors):.2%}")
        
        # è¯„åˆ¤æ ‡å‡†
        if np.mean(relative_errors) < 0.1:
            logger.info("  âœ“ é‡å»ºè´¨é‡: ä¼˜ç§€ (ç›¸å¯¹è¯¯å·® < 10%)")
        elif np.mean(relative_errors) < 0.2:
            logger.info("  âœ“ é‡å»ºè´¨é‡: è‰¯å¥½ (ç›¸å¯¹è¯¯å·® < 20%)")
        else:
            logger.info("  âœ— é‡å»ºè´¨é‡: éœ€æ”¹è¿› (ç›¸å¯¹è¯¯å·® >= 20%)")
    
    return {'mean_error': np.mean(errors), 'mean_rel_error': np.mean(relative_errors)}


@torch.no_grad()
def validate_health_score_curve(model, latent_vectors, cycles, num_samples=20, device='cuda'):
    """
    éªŒè¯ 2: å¥åº·è¯„åˆ†æ›²çº¿
    
    æ£€æŸ¥é¢„æµ‹çš„å¥åº·æ›²çº¿æ˜¯å¦æ»¡è¶³:
    1. å•è°ƒé€’å¢ (é€€åŒ–åº”è¯¥è¶Šæ¥è¶Šä¸¥é‡)
    2. èŒƒå›´åœ¨ [0, 1] å†…
    3. æ—©æœŸ cycle è¯„åˆ†ä½ï¼Œæ™šæœŸ cycle è¯„åˆ†é«˜
    """
    logger.info("=" * 60)
    logger.info("éªŒè¯ 2: å¥åº·è¯„åˆ†æ›²çº¿ (å•è°ƒæ€§ & ç‰©ç†æ„ä¹‰)")
    logger.info("=" * 60)
    
    monotonic_count = 0
    valid_range_count = 0
    early_late_correct = 0
    
    # è·å–æ—©æœŸå’Œæ™šæœŸçš„ cycle
    min_cycle = cycles.min().item()
    max_cycle = cycles.max().item()
    early_threshold = min_cycle + (max_cycle - min_cycle) * 0.2
    late_threshold = min_cycle + (max_cycle - min_cycle) * 0.8
    
    for _ in range(num_samples):
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ—©æœŸæ ·æœ¬
        early_mask = cycles <= early_threshold
        early_indices = torch.where(early_mask)[0]
        if len(early_indices) == 0:
            continue
        
        idx = early_indices[np.random.randint(len(early_indices))].item()
        z_0 = latent_vectors[idx:idx+1].to(device)
        
        # é¢„æµ‹è½¨è¿¹
        t_span = torch.linspace(0, 1, 100, device=device)
        trajectory = model.predict_trajectory(z_0, t_span)
        
        # è®¡ç®—å¥åº·è¯„åˆ†
        health_scores = []
        for z_t in trajectory:
            score = model.health_head(z_t).squeeze().item()
            health_scores.append(score)
        
        health_scores = np.array(health_scores)
        
        # æ£€æŸ¥å•è°ƒæ€§ (å…è®¸ä¸€äº›æ³¢åŠ¨)
        diffs = np.diff(health_scores)
        monotonic_ratio = np.mean(diffs >= -0.01)  # å…è®¸å¾®å°ä¸‹é™
        if monotonic_ratio > 0.9:
            monotonic_count += 1
        
        # æ£€æŸ¥èŒƒå›´
        if health_scores.min() >= -0.1 and health_scores.max() <= 1.1:
            valid_range_count += 1
        
        # æ£€æŸ¥æ—©æœŸä½ã€æ™šæœŸé«˜
        early_score = health_scores[:20].mean()
        late_score = health_scores[-20:].mean()
        if late_score > early_score:
            early_late_correct += 1
    
    logger.info(f"  é‡‡æ ·æ•°: {num_samples}")
    logger.info(f"  å•è°ƒé€’å¢æ¯”ä¾‹: {monotonic_count}/{num_samples} ({monotonic_count/num_samples:.1%})")
    logger.info(f"  èŒƒå›´æœ‰æ•ˆæ¯”ä¾‹: {valid_range_count}/{num_samples} ({valid_range_count/num_samples:.1%})")
    logger.info(f"  æ—©ä½æ™šé«˜æ¯”ä¾‹: {early_late_correct}/{num_samples} ({early_late_correct/num_samples:.1%})")
    
    if monotonic_count/num_samples > 0.8 and early_late_correct/num_samples > 0.9:
        logger.info("  âœ“ å¥åº·æ›²çº¿ç¬¦åˆç‰©ç†æ„ä¹‰")
    else:
        logger.info("  âœ— å¥åº·æ›²çº¿éœ€è¦æ£€æŸ¥")
    
    return {
        'monotonic_ratio': monotonic_count/num_samples,
        'valid_range_ratio': valid_range_count/num_samples,
        'early_late_ratio': early_late_correct/num_samples,
    }


@torch.no_grad()
def validate_latent_space_structure(model, latent_vectors, cycles, device='cuda'):
    """
    éªŒè¯ 3: æ½œç©ºé—´ç»“æ„
    
    æ£€æŸ¥:
    1. ä¸åŒ cycle çš„æ½œå‘é‡æ˜¯å¦æœ‰åºåˆ†å¸ƒ
    2. è½¨è¿¹æ˜¯å¦å¹³æ»‘è¿ç»­
    """
    logger.info("=" * 60)
    logger.info("éªŒè¯ 3: æ½œç©ºé—´ç»“æ„")
    logger.info("=" * 60)
    
    try:
        from sklearn.decomposition import PCA
        import matplotlib.pyplot as plt
    except ImportError:
        logger.warning("éœ€è¦ sklearn å’Œ matplotlib è¿›è¡Œå¯è§†åŒ–")
        return {}
    
    # PCA é™ç»´
    latent_np = latent_vectors.cpu().numpy()
    cycles_np = cycles.cpu().numpy()
    
    pca = PCA(n_components=2)
    latent_2d = pca.fit_transform(latent_np)
    
    # è®¡ç®—è§£é‡Šæ–¹å·®
    explained_var = pca.explained_variance_ratio_.sum()
    logger.info(f"  PCA 2D è§£é‡Šæ–¹å·®: {explained_var:.1%}")
    
    # è®¡ç®— cycle ä¸ PC1 çš„ç›¸å…³æ€§
    from scipy.stats import spearmanr
    corr, p_value = spearmanr(cycles_np, latent_2d[:, 0])
    logger.info(f"  Cycle vs PC1 ç›¸å…³æ€§: {corr:.3f} (p={p_value:.2e})")
    
    if abs(corr) > 0.5:
        logger.info("  âœ“ æ½œç©ºé—´ç»“æ„: cycle ä¸ PC1 æ˜¾è‘—ç›¸å…³ï¼Œè¯´æ˜é€€åŒ–æ–¹å‘å·²è¢«å­¦ä¹ ")
    else:
        logger.info("  âš  æ½œç©ºé—´ç»“æ„: cycle ä¸ PC1 ç›¸å…³æ€§è¾ƒå¼±")
    
    # å¯è§†åŒ–
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # å·¦å›¾: æ‰€æœ‰æ ·æœ¬çš„æ½œç©ºé—´åˆ†å¸ƒ
    scatter = axes[0].scatter(latent_2d[:, 0], latent_2d[:, 1], c=cycles_np, cmap='viridis', alpha=0.6)
    axes[0].set_xlabel('PC1')
    axes[0].set_ylabel('PC2')
    axes[0].set_title('Latent Space Distribution (colored by Cycle)')
    plt.colorbar(scatter, ax=axes[0], label='Cycle')
    
    # å³å›¾: é¢„æµ‹è½¨è¿¹
    # é€‰æ‹©ä¸€ä¸ªæ—©æœŸæ ·æœ¬ï¼Œé¢„æµ‹å…¶è½¨è¿¹
    early_idx = cycles_np.argmin()
    z_0 = latent_vectors[early_idx:early_idx+1].to(device)
    t_span = torch.linspace(0, 1, 100, device=device)
    trajectory = model.predict_trajectory(z_0, t_span).cpu().numpy()[:, 0, :]
    trajectory_2d = pca.transform(trajectory)
    
    axes[1].scatter(latent_2d[:, 0], latent_2d[:, 1], c=cycles_np, cmap='viridis', alpha=0.3)
    axes[1].plot(trajectory_2d[:, 0], trajectory_2d[:, 1], 'r-', linewidth=2, label='Predicted Trajectory')
    axes[1].scatter(trajectory_2d[0, 0], trajectory_2d[0, 1], c='green', s=100, marker='o', label='Start (t=0)')
    axes[1].scatter(trajectory_2d[-1, 0], trajectory_2d[-1, 1], c='red', s=100, marker='x', label='End (t=1)')
    axes[1].set_xlabel('PC1')
    axes[1].set_ylabel('PC2')
    axes[1].set_title('Predicted Trajectory in Latent Space')
    axes[1].legend()
    
    plt.tight_layout()
    
    # ä¿å­˜
    save_path = Path('experiments/flow_matching/validation')
    save_path.mkdir(parents=True, exist_ok=True)
    plt.savefig(save_path / 'latent_space_validation.png', dpi=150, bbox_inches='tight')
    logger.info(f"  å¯è§†åŒ–å·²ä¿å­˜: {save_path / 'latent_space_validation.png'}")
    plt.close()
    
    return {'explained_variance': explained_var, 'cycle_pc1_correlation': corr}


@torch.no_grad()
def validate_rul_prediction(model, latent_vectors, cycles, num_samples=50, device='cuda'):
    """
    éªŒè¯ 4: RUL é¢„æµ‹ç²¾åº¦
    
    å¯¹äºå·²çŸ¥ cycle çš„æ ·æœ¬ï¼Œé¢„æµ‹å…¶åˆ°è¾¾æŸä¸ª "å¤±æ•ˆ" ç‚¹çš„ cycle æ•°
    """
    logger.info("=" * 60)
    logger.info("éªŒè¯ 4: RUL (å‰©ä½™å¯¿å‘½) é¢„æµ‹èƒ½åŠ›")
    logger.info("=" * 60)
    
    max_cycle = cycles.max().item()
    min_cycle = cycles.min().item()
    
    # é€‰æ‹©ä¸­é—´é˜¶æ®µçš„æ ·æœ¬ä½œä¸ºæµ‹è¯•
    mid_start = min_cycle + (max_cycle - min_cycle) * 0.3
    mid_end = min_cycle + (max_cycle - min_cycle) * 0.6
    
    test_mask = (cycles >= mid_start) & (cycles <= mid_end)
    test_indices = torch.where(test_mask)[0]
    
    if len(test_indices) == 0:
        logger.warning("  æ²¡æœ‰è¶³å¤Ÿçš„ä¸­æœŸæ ·æœ¬è¿›è¡Œ RUL éªŒè¯")
        return {}
    
    # éšæœºé‡‡æ ·
    sample_indices = test_indices[torch.randperm(len(test_indices))[:min(num_samples, len(test_indices))]]
    
    rul_errors = []
    
    for idx in sample_indices:
        current_cycle = cycles[idx].item()
        z_0 = latent_vectors[idx:idx+1].to(device)
        
        # çœŸå® RUL (åˆ°æœ€å¤§ cycle)
        true_rul = max_cycle - current_cycle
        
        # é¢„æµ‹ RUL
        t_current = current_cycle / max_cycle
        t_span = torch.linspace(t_current, 1.0, 50, device=device)
        trajectory = model.predict_trajectory(z_0, t_span)
        
        # è®¡ç®—å¥åº·è¯„åˆ†
        health_scores = []
        for z_t in trajectory:
            score = model.health_head(z_t).squeeze().item()
            health_scores.append(score)
        
        health_scores = np.array(health_scores)
        
        # æ‰¾åˆ°è¶…è¿‡é˜ˆå€¼çš„ç‚¹ (å‡è®¾ 0.8 ä¸ºå¤±æ•ˆé˜ˆå€¼)
        threshold = 0.8
        failure_indices = np.where(health_scores >= threshold)[0]
        
        if len(failure_indices) > 0:
            failure_t = t_span[failure_indices[0]].item()
            predicted_failure_cycle = failure_t * max_cycle
            predicted_rul = predicted_failure_cycle - current_cycle
        else:
            predicted_rul = max_cycle - current_cycle  # æœªåˆ°é˜ˆå€¼
        
        rul_error = abs(predicted_rul - true_rul)
        rul_errors.append(rul_error)
    
    if rul_errors:
        logger.info(f"  æµ‹è¯•æ ·æœ¬æ•°: {len(rul_errors)}")
        logger.info(f"  RUL è¯¯å·® (cycles): {np.mean(rul_errors):.1f} Â± {np.std(rul_errors):.1f}")
        logger.info(f"  RUL ç›¸å¯¹è¯¯å·®: {np.mean(rul_errors)/max_cycle:.1%}")
        
        if np.mean(rul_errors)/max_cycle < 0.15:
            logger.info("  âœ“ RUL é¢„æµ‹: ç²¾åº¦è¾ƒå¥½ (< 15% è¯¯å·®)")
        else:
            logger.info("  âš  RUL é¢„æµ‹: è¯¯å·®è¾ƒå¤§ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ")
    
    return {'mean_rul_error': np.mean(rul_errors) if rul_errors else None}


def generate_demo_prediction(model, latent_vectors, cycles, device='cuda'):
    """
    ç”Ÿæˆæ¼”ç¤ºé¢„æµ‹å›¾
    
    å±•ç¤ºä»ä¸åŒåˆå§‹ cycle å‡ºå‘çš„é¢„æµ‹è½¨è¿¹
    """
    logger.info("=" * 60)
    logger.info("ç”Ÿæˆæ¼”ç¤ºé¢„æµ‹å›¾")
    logger.info("=" * 60)
    
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        logger.warning("éœ€è¦ matplotlib")
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    max_cycle = cycles.max().item()
    
    # é€‰æ‹©ä¸åŒé˜¶æ®µçš„èµ·ç‚¹
    percentiles = [0.1, 0.3, 0.5, 0.7]
    colors = ['blue', 'green', 'orange', 'red']
    
    for ax_idx, (pct, color) in enumerate(zip(percentiles, colors)):
        ax = axes[ax_idx // 2, ax_idx % 2]
        
        target_cycle = cycles.min().item() + (max_cycle - cycles.min().item()) * pct
        idx = (torch.abs(cycles - target_cycle)).argmin().item()
        start_cycle = cycles[idx].item()
        
        z_0 = latent_vectors[idx:idx+1].to(device)
        
        # é¢„æµ‹è½¨è¿¹
        t_start = start_cycle / max_cycle
        t_span = torch.linspace(t_start, 1.0, 100, device=device)
        trajectory = model.predict_trajectory(z_0, t_span)
        
        # è®¡ç®—å¥åº·è¯„åˆ†
        health_scores = []
        for z_t in trajectory:
            score = model.health_head(z_t).squeeze().item()
            health_scores.append(score)
        
        predicted_cycles = t_span.cpu().numpy() * max_cycle
        
        ax.plot(predicted_cycles, health_scores, color=color, linewidth=2, 
                label=f'From Cycle {int(start_cycle)}')
        ax.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='Failure Threshold')
        ax.axvline(x=start_cycle, color=color, linestyle=':', alpha=0.5)
        
        ax.set_xlabel('Cycle')
        ax.set_ylabel('Health Score (Degradation)')
        ax.set_title(f'Starting from Cycle {int(start_cycle)} ({pct:.0%} of lifecycle)')
        ax.set_ylim(-0.05, 1.05)
        ax.legend()
        ax.grid(True, alpha=0.3)
    
    plt.suptitle('Flow Matching Lifecycle Predictions', fontsize=14)
    plt.tight_layout()
    
    save_path = Path('experiments/flow_matching/validation')
    save_path.mkdir(parents=True, exist_ok=True)
    plt.savefig(save_path / 'lifecycle_predictions.png', dpi=150, bbox_inches='tight')
    logger.info(f"  é¢„æµ‹å›¾å·²ä¿å­˜: {save_path / 'lifecycle_predictions.png'}")
    plt.close()


def main():
    parser = argparse.ArgumentParser(description="Flow Matching Model Validation")
    parser.add_argument('--checkpoint', type=str, required=True, help='Flow Matching æ¨¡å‹æ£€æŸ¥ç‚¹')
    parser.add_argument('--encoder_checkpoint', type=str, default='latest.pth', help='Encoder æ£€æŸ¥ç‚¹')
    parser.add_argument('--cache_dir', type=str, default='experiments/flow_matching/cache', 
                        help='æ½œç©ºé—´ç¼“å­˜ç›®å½•')
    parser.add_argument('--device', type=str, default='cuda', help='è®¾å¤‡')
    args = parser.parse_args()
    
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. åŠ è½½ Encoder
    logger.info("åŠ è½½ Encoder...")
    encoder, latent_dim = load_encoder(args.encoder_checkpoint, device)
    
    # 2. åŠ è½½ Flow Matching æ¨¡å‹
    logger.info("åŠ è½½ Flow Matching æ¨¡å‹...")
    model, config = load_flow_model(args.checkpoint, encoder, latent_dim, device)
    
    # 3. åŠ è½½æ½œç©ºé—´ç¼“å­˜
    logger.info("åŠ è½½æ½œç©ºé—´ç¼“å­˜...")
    cache_dir = Path(args.cache_dir)
    if not (cache_dir / 'latent_vectors.pt').exists():
        logger.error(f"ç¼“å­˜ä¸å­˜åœ¨: {cache_dir}")
        logger.info("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆç¼“å­˜: python scripts/train_flow.py --compute_cache")
        return
    
    cache_data = torch.load(cache_dir / 'latent_vectors.pt')
    latent_vectors = cache_data['latent_vectors']
    cycles = cache_data['cycles']
    
    logger.info(f"åŠ è½½ {len(latent_vectors)} ä¸ªæ½œå‘é‡")
    logger.info(f"Cycle èŒƒå›´: {cycles.min().item()} - {cycles.max().item()}")
    
    # 4. è¿è¡ŒéªŒè¯
    logger.info("\n" + "=" * 60)
    logger.info("å¼€å§‹ Flow Matching æ¨¡å‹éªŒè¯")
    logger.info("=" * 60 + "\n")
    
    results = {}
    
    # éªŒè¯ 1: è½¨è¿¹é‡å»º
    results['reconstruction'] = validate_trajectory_reconstruction(
        model, latent_vectors, cycles, num_samples=100, device=device
    )
    
    # éªŒè¯ 2: å¥åº·æ›²çº¿
    results['health_curve'] = validate_health_score_curve(
        model, latent_vectors, cycles, num_samples=20, device=device
    )
    
    # éªŒè¯ 3: æ½œç©ºé—´ç»“æ„
    results['latent_structure'] = validate_latent_space_structure(
        model, latent_vectors, cycles, device=device
    )
    
    # éªŒè¯ 4: RUL é¢„æµ‹
    results['rul'] = validate_rul_prediction(
        model, latent_vectors, cycles, num_samples=50, device=device
    )
    
    # ç”Ÿæˆæ¼”ç¤ºå›¾
    generate_demo_prediction(model, latent_vectors, cycles, device=device)
    
    # æ€»ç»“
    logger.info("\n" + "=" * 60)
    logger.info("éªŒè¯æ€»ç»“")
    logger.info("=" * 60)
    
    all_passed = True
    
    if results['reconstruction'].get('mean_rel_error', 1) < 0.2:
        logger.info("âœ“ è½¨è¿¹é‡å»º: é€šè¿‡")
    else:
        logger.info("âœ— è½¨è¿¹é‡å»º: éœ€æ”¹è¿›")
        all_passed = False
    
    if results['health_curve'].get('monotonic_ratio', 0) > 0.8:
        logger.info("âœ“ å¥åº·æ›²çº¿: é€šè¿‡")
    else:
        logger.info("âœ— å¥åº·æ›²çº¿: éœ€æ”¹è¿›")
        all_passed = False
    
    if abs(results['latent_structure'].get('cycle_pc1_correlation', 0)) > 0.5:
        logger.info("âœ“ æ½œç©ºé—´ç»“æ„: é€šè¿‡")
    else:
        logger.info("âš  æ½œç©ºé—´ç»“æ„: ç›¸å…³æ€§è¾ƒå¼±")
    
    if all_passed:
        logger.info("\nğŸ‰ æ¨¡å‹éªŒè¯é€šè¿‡ï¼å¯ä»¥è¿›è¡Œæ¨ç†éƒ¨ç½²ã€‚")
    else:
        logger.info("\nâš  éƒ¨åˆ†éªŒè¯æœªé€šè¿‡ï¼Œå»ºè®®ç»§ç»­è®­ç»ƒæˆ–è°ƒæ•´è¶…å‚æ•°ã€‚")


if __name__ == "__main__":
    main()
